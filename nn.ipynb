{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!conda install -y -c conda-forge skorch\r\n",
        "!conda install -y pytorch torchvision torchaudio cpuonly -c pytorch\r\n",
        "!pip install nb_black"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "from pathlib import Path\r\n",
        "\r\n",
        "import joblib\r\n",
        "import matplotlib as mpl\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.utils.data\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.svm import SVC\r\n",
        "from skorch import NeuralNetClassifier, classifier\r\n",
        "from skorch.callbacks import EarlyStopping\r\n",
        "from skorch.helper import predefined_split\r\n",
        "from torch.nn.modules.loss import L1Loss\r\n",
        "from torch.optim import SGD, Adam, RMSprop\r\n",
        "\r\n",
        "%load_ext nb_black"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"from pathlib import Path\\n\\nimport joblib\\nimport matplotlib as mpl\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torch.utils.data\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_curve\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.svm import SVC\\nfrom skorch import NeuralNetClassifier, classifier\\nfrom skorch.callbacks import EarlyStopping\\nfrom skorch.helper import predefined_split\\nfrom torch.nn.modules.loss import L1Loss\\nfrom torch.optim import SGD, Adam, RMSprop\\n\\n%load_ext nb_black\";\n                var nbb_formatted_code = \"from pathlib import Path\\n\\nimport joblib\\nimport matplotlib as mpl\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd\\nimport seaborn as sns\\nimport torch\\nimport torch.nn as nn\\nimport torch.nn.functional as F\\nimport torch.utils.data\\nimport torchvision\\nimport torchvision.transforms as transforms\\nfrom sklearn.metrics import accuracy_score, confusion_matrix, roc_curve\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.svm import SVC\\nfrom skorch import NeuralNetClassifier, classifier\\nfrom skorch.callbacks import EarlyStopping\\nfrom skorch.helper import predefined_split\\nfrom torch.nn.modules.loss import L1Loss\\nfrom torch.optim import SGD, Adam, RMSprop\\n\\n%load_ext nb_black\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "gather": {
          "logged": 1629884795585
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "transformations = torchvision.transforms.Compose(\r\n",
        "    [\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize((0.1307), ((0.3081))),\r\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\r\n",
        "        transforms.RandomVerticalFlip(p=0.5),\r\n",
        "        transforms.GaussianBlur(kernel_size=3),\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "training_data = torchvision.datasets.MNIST(root=Path(\"nn_mnist\", \"data\"), train=True, download=True, transform=transformations)\r\n",
        "test_data = torchvision.datasets.MNIST(root=Path(\"nn_mnist\", \"data\"), train=False, download=True, transform=transforms.ToTensor())\r\n",
        "\r\n",
        "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=60000, shuffle=True, num_workers=0)\r\n",
        "\r\n",
        "# Take batch and label from train dataloader\r\n",
        "train_dataloader_batch = next(iter(train_dataloader))\r\n",
        "X_train = train_dataloader_batch[0].numpy()\r\n",
        "y_train = train_dataloader_batch[1].numpy()\r\n",
        "\r\n",
        "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=10000, shuffle=False, num_workers=0)\r\n",
        "test_dataloader_batch = next(iter(test_dataloader))\r\n",
        "X_test = test_dataloader_batch[0].numpy()\r\n",
        "y_test = test_dataloader_batch[1].numpy()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"transformations = torchvision.transforms.Compose(\\n    [\\n        transforms.ToTensor(),\\n        transforms.Normalize((0.1307), ((0.3081))),\\n        transforms.RandomHorizontalFlip(p=0.5),\\n        transforms.RandomVerticalFlip(p=0.5),\\n        transforms.GaussianBlur(kernel_size=3),\\n    ]\\n)\\n\\ntraining_data = torchvision.datasets.MNIST(root=Path(\\\"nn_mnist\\\", \\\"data\\\"), train=True, download=True, transform=transformations)\\ntest_data = torchvision.datasets.MNIST(root=Path(\\\"nn_mnist\\\", \\\"data\\\"), train=False, download=True, transform=transforms.ToTensor())\\n\\ntrain_dataloader = torch.utils.data.DataLoader(training_data, batch_size=60000, shuffle=True, num_workers=0)\\n\\n# Take batch and label from train dataloader\\ntrain_dataloader_batch = next(iter(train_dataloader))\\nX_train = train_dataloader_batch[0].numpy()\\ny_train = train_dataloader_batch[1].numpy()\\n\\ntest_dataloader = torch.utils.data.DataLoader(test_data, batch_size=10000, shuffle=False, num_workers=0)\\ntest_dataloader_batch = next(iter(test_dataloader))\\nX_test = test_dataloader_batch[0].numpy()\\ny_test = test_dataloader_batch[1].numpy()\";\n                var nbb_formatted_code = \"transformations = torchvision.transforms.Compose(\\n    [\\n        transforms.ToTensor(),\\n        transforms.Normalize((0.1307), ((0.3081))),\\n        transforms.RandomHorizontalFlip(p=0.5),\\n        transforms.RandomVerticalFlip(p=0.5),\\n        transforms.GaussianBlur(kernel_size=3),\\n    ]\\n)\\n\\ntraining_data = torchvision.datasets.MNIST(\\n    root=Path(\\\"nn_mnist\\\", \\\"data\\\"), train=True, download=True, transform=transformations\\n)\\ntest_data = torchvision.datasets.MNIST(\\n    root=Path(\\\"nn_mnist\\\", \\\"data\\\"),\\n    train=False,\\n    download=True,\\n    transform=transforms.ToTensor(),\\n)\\n\\ntrain_dataloader = torch.utils.data.DataLoader(\\n    training_data, batch_size=60000, shuffle=True, num_workers=0\\n)\\n\\n# Take batch and label from train dataloader\\ntrain_dataloader_batch = next(iter(train_dataloader))\\nX_train = train_dataloader_batch[0].numpy()\\ny_train = train_dataloader_batch[1].numpy()\\n\\ntest_dataloader = torch.utils.data.DataLoader(\\n    test_data, batch_size=10000, shuffle=False, num_workers=0\\n)\\ntest_dataloader_batch = next(iter(test_dataloader))\\nX_test = test_dataloader_batch[0].numpy()\\ny_test = test_dataloader_batch[1].numpy()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629884825617
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "class MLP(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super().__init__()\r\n",
        "        self.fc1 = nn.Linear(28 * 28 * 1, 300)\r\n",
        "        self.fc2 = nn.Linear(300, 100)\r\n",
        "        self.fc3 = nn.Linear(100, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = x.view(-1, 28 * 28 * 1)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "\r\n",
        "net = NeuralNetClassifier(MLP, callbacks=[EarlyStopping()], criterion=nn.CrossEntropyLoss, max_epochs=50)\r\n",
        "\r\n",
        "parameters = [\r\n",
        "    {\r\n",
        "        \"lr\": [0.1, 0.001, 0.001],\r\n",
        "        \"optimizer\": [SGD],\r\n",
        "        \"optimizer__momentum\": [0.3, 0.6, 0.9],\r\n",
        "    },\r\n",
        "    {\r\n",
        "        \"lr\": [0.1, 0.001, 0.001],\r\n",
        "        \"optimizer\": [Adam],\r\n",
        "    },\r\n",
        "]\r\n",
        "\r\n",
        "gs = GridSearchCV(\r\n",
        "    net,\r\n",
        "    parameters,\r\n",
        "    refit=True,\r\n",
        "    cv=5,\r\n",
        "    return_train_score=True,\r\n",
        "    verbose=3,\r\n",
        "    scoring=\"accuracy\",\r\n",
        "    n_jobs=-1,\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "gs.fit(X_train, y_train)\r\n",
        "\r\n",
        "joblib.dump(gs, Path(\"nn_mnist\", \"results\", \"NN_gs.pkl\"))\r\n",
        "gs.best_estimator_.save_params(f_params=Path(\"nn_mnist\", \"results\", \"NN_weights.pkl\"))\r\n",
        "\r\n",
        "# Grid Search Parameter Table\r\n",
        "grid_table = pd.concat(\r\n",
        "    [\r\n",
        "        pd.DataFrame(gs.cv_results_[\"params\"]),\r\n",
        "        pd.DataFrame(gs.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]),\r\n",
        "    ],\r\n",
        "    axis=1,\r\n",
        ")\r\n",
        "\r\n",
        "grid_table.to_csv(Path(\"nn_mnist\", \"results\", \"NN_grid_table.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m0.6825\u001b[0m       \u001b[32m0.8815\u001b[0m        \u001b[35m0.3632\u001b[0m  1.4399\n",
            "      2        \u001b[36m0.2816\u001b[0m       \u001b[32m0.9078\u001b[0m        \u001b[35m0.2860\u001b[0m  1.0634\n",
            "      3        \u001b[36m0.2014\u001b[0m       \u001b[32m0.9194\u001b[0m        \u001b[35m0.2512\u001b[0m  1.1279\n",
            "      4        \u001b[36m0.1547\u001b[0m       \u001b[32m0.9278\u001b[0m        \u001b[35m0.2275\u001b[0m  1.1674\n",
            "      5        \u001b[36m0.1230\u001b[0m       \u001b[32m0.9293\u001b[0m        0.2307  1.1517\n",
            "      6        \u001b[36m0.0989\u001b[0m       \u001b[32m0.9339\u001b[0m        \u001b[35m0.2242\u001b[0m  1.1857\n",
            "      7        \u001b[36m0.0800\u001b[0m       0.9328        0.2358  1.1461\n",
            "      8        \u001b[36m0.0650\u001b[0m       \u001b[32m0.9353\u001b[0m        0.2422  1.3187\n",
            "      9        \u001b[36m0.0541\u001b[0m       \u001b[32m0.9360\u001b[0m        0.2512  1.1430\n",
            "     10        \u001b[36m0.0455\u001b[0m       0.9319        0.2705  1.2005\n",
            "Stopping since valid_loss has not improved in the last 5 epochs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  60 | elapsed:   55.3s remaining:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done  28 out of  60 | elapsed:  1.8min remaining:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done  49 out of  60 | elapsed:  2.7min remaining:   36.0s\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  2.8min finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"class MLP(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.fc1 = nn.Linear(28 * 28 * 1, 300)\\n        self.fc2 = nn.Linear(300, 100)\\n        self.fc3 = nn.Linear(100, 10)\\n\\n    def forward(self, x):\\n        x = x.view(-1, 28 * 28 * 1)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\n\\nnet = NeuralNetClassifier(MLP, callbacks=[EarlyStopping()], criterion=nn.CrossEntropyLoss, max_epochs=50)\\n\\nparameters = [\\n    {\\n        \\\"lr\\\": [0.1, 0.001, 0.001],\\n        \\\"optimizer\\\": [SGD],\\n        \\\"optimizer__momentum\\\": [0.3, 0.6, 0.9],\\n    },\\n    {\\n        \\\"lr\\\": [0.1, 0.001, 0.001],\\n        \\\"optimizer\\\": [Adam],\\n    },\\n]\\n\\ngs = GridSearchCV(\\n    net,\\n    parameters,\\n    refit=True,\\n    cv=5,\\n    return_train_score=True,\\n    verbose=3,\\n    scoring=\\\"accuracy\\\",\\n    n_jobs=-1,\\n)\\n\\n\\ngs.fit(X_train, y_train)\\n\\njoblib.dump(gs, Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"gs.pkl\\\"))\\ngs.best_estimator_.save_params(f_params=Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"weights.pkl\\\"))\\n\\n# Grid Search Parameter Table\\ngrid_table = pd.concat(\\n    [\\n        pd.DataFrame(gs.cv_results_[\\\"params\\\"]),\\n        pd.DataFrame(gs.cv_results_[\\\"mean_test_score\\\"], columns=[\\\"Accuracy\\\"]),\\n    ],\\n    axis=1,\\n)\\n\\ngrid_table.to_csv(Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"grid_table.csv\\\"))\";\n                var nbb_formatted_code = \"class MLP(nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n        self.fc1 = nn.Linear(28 * 28 * 1, 300)\\n        self.fc2 = nn.Linear(300, 100)\\n        self.fc3 = nn.Linear(100, 10)\\n\\n    def forward(self, x):\\n        x = x.view(-1, 28 * 28 * 1)\\n        x = F.relu(self.fc1(x))\\n        x = F.relu(self.fc2(x))\\n        x = self.fc3(x)\\n        return x\\n\\n\\nnet = NeuralNetClassifier(\\n    MLP, callbacks=[EarlyStopping()], criterion=nn.CrossEntropyLoss, max_epochs=50\\n)\\n\\nparameters = [\\n    {\\n        \\\"lr\\\": [0.1, 0.001, 0.001],\\n        \\\"optimizer\\\": [SGD],\\n        \\\"optimizer__momentum\\\": [0.3, 0.6, 0.9],\\n    },\\n    {\\n        \\\"lr\\\": [0.1, 0.001, 0.001],\\n        \\\"optimizer\\\": [Adam],\\n    },\\n]\\n\\ngs = GridSearchCV(\\n    net,\\n    parameters,\\n    refit=True,\\n    cv=5,\\n    return_train_score=True,\\n    verbose=3,\\n    scoring=\\\"accuracy\\\",\\n    n_jobs=-1,\\n)\\n\\n\\ngs.fit(X_train, y_train)\\n\\njoblib.dump(gs, Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"gs.pkl\\\"))\\ngs.best_estimator_.save_params(f_params=Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"weights.pkl\\\"))\\n\\n# Grid Search Parameter Table\\ngrid_table = pd.concat(\\n    [\\n        pd.DataFrame(gs.cv_results_[\\\"params\\\"]),\\n        pd.DataFrame(gs.cv_results_[\\\"mean_test_score\\\"], columns=[\\\"Accuracy\\\"]),\\n    ],\\n    axis=1,\\n)\\n\\ngrid_table.to_csv(Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"grid_table.csv\\\"))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629885012470
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "gs = joblib.load(Path(\"nn_mnist\", \"results\", \"NN_gs.pkl\"))\r\n",
        "\r\n",
        "Net = gs.best_estimator_.initialize()\r\n",
        "Net.load_params(Path(\"nn_mnist\", \"results\", \"NN_weights.pkl\"))\r\n",
        "Net.check_is_fitted\r\n",
        "\r\n",
        "y_pred = Net.predict(X_test)\r\n",
        "accuracy = accuracy_score(y_test, y_pred)\r\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'joblib' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-e6e8bb9d2629>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nn_mnist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"results\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NN_gs.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mNet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nn_mnist\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"results\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NN_weights.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'joblib' is not defined"
          ]
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629885019114
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "SVM = SVC(\r\n",
        "    gamma='scale',\r\n",
        ")\r\n",
        "\r\n",
        "params = [\r\n",
        "    {\r\n",
        "        \"kernel\": [\"rbf\", \"linear\"], \r\n",
        "        \"C\": [3, 6, 9],\r\n",
        "    }\r\n",
        "]\r\n",
        "\r\n",
        "\r\n",
        "SVM_gs = GridSearchCV(\r\n",
        "    SVM,\r\n",
        "    param_grid=params,\r\n",
        "    refit=True,\r\n",
        "    cv=2,\r\n",
        "    return_train_score=True,\r\n",
        "    verbose=3,\r\n",
        "    scoring=\"balanced_accuracy\",\r\n",
        "    n_jobs=-1,\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "X_train_flat = X_train.squeeze().reshape((60000, 28 * 28))\r\n",
        "\r\n",
        "SVM_gs.fit(X_train_flat, y_train)\r\n",
        "\r\n",
        "joblib.dump(SVM_gs, Path(\"nn_mnist\", \"results\", \"SVM_gs.pkl\"))\r\n",
        "\r\n",
        "grid_table = pd.concat(\r\n",
        "    [\r\n",
        "        pd.DataFrame(SVM_gs.cv_results_[\"params\"]),\r\n",
        "        pd.DataFrame(SVM_gs.cv_results_[\"mean_test_score\"], columns=[\"Accuracy\"]),\r\n",
        "    ],\r\n",
        "    axis=1,\r\n",
        ")\r\n",
        "\r\n",
        "grid_table.to_csv(Path(\"nn_mnist\", \"results\", \"SVM_grid_table.csv\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 48 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of  12 | elapsed: 17.2min remaining: 86.2min\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed: 40.6min remaining: 29.0min\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 77.6min remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed: 77.6min finished\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"SVM = SVC(\\n    gamma='scale',\\n)\\n\\nparams = [\\n    {\\n        \\\"kernel\\\": [\\\"rbf\\\", \\\"linear\\\"], \\n        \\\"C\\\": [3, 6, 9],\\n    }\\n]\\n\\n\\nSVM_gs = GridSearchCV(\\n    SVM,\\n    param_grid=params,\\n    refit=True,\\n    cv=2,\\n    return_train_score=True,\\n    verbose=3,\\n    scoring=\\\"balanced_accuracy\\\",\\n    n_jobs=-1,\\n)\\n\\n\\nX_train_flat = X_train.squeeze().reshape((60000, 28 * 28))\\n\\nSVM_gs.fit(X_train_flat, y_train)\\n\\njoblib.dump(SVM_gs, Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"SVM_gs.pkl\\\"))\\n\\ngrid_table = pd.concat(\\n    [\\n        pd.DataFrame(SVM_gs.cv_results_[\\\"params\\\"]),\\n        pd.DataFrame(SVM_gs.cv_results_[\\\"mean_test_score\\\"], columns=[\\\"Accuracy\\\"]),\\n    ],\\n    axis=1,\\n)\\n\\ngrid_table.to_csv(Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"SVM_grid_table.csv\\\"))\";\n                var nbb_formatted_code = \"SVM = SVC(\\n    gamma=\\\"scale\\\",\\n)\\n\\nparams = [\\n    {\\n        \\\"kernel\\\": [\\\"rbf\\\", \\\"linear\\\"],\\n        \\\"C\\\": [3, 6, 9],\\n    }\\n]\\n\\n\\nSVM_gs = GridSearchCV(\\n    SVM,\\n    param_grid=params,\\n    refit=True,\\n    cv=2,\\n    return_train_score=True,\\n    verbose=3,\\n    scoring=\\\"balanced_accuracy\\\",\\n    n_jobs=-1,\\n)\\n\\n\\nX_train_flat = X_train.squeeze().reshape((60000, 28 * 28))\\n\\nSVM_gs.fit(X_train_flat, y_train)\\n\\njoblib.dump(SVM_gs, Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"SVM_gs.pkl\\\"))\\n\\ngrid_table = pd.concat(\\n    [\\n        pd.DataFrame(SVM_gs.cv_results_[\\\"params\\\"]),\\n        pd.DataFrame(SVM_gs.cv_results_[\\\"mean_test_score\\\"], columns=[\\\"Accuracy\\\"]),\\n    ],\\n    axis=1,\\n)\\n\\ngrid_table.to_csv(Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"SVM_grid_table.csv\\\"))\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629890404800
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "gs = joblib.load(Path(\"nn_mnist\", \"results\", \"SVM_gs.pkl\"))\r\n",
        "\r\n",
        "X_test_flat = X_test.squeeze().reshape((10000, 28 * 28))\r\n",
        "\r\n",
        "y_pred = SVM_gs.best_estimator_.predict(X_test_flat)\r\n",
        "accuracy = accuracy_score(y_test, y_pred)\r\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 14;\n                var nbb_unformatted_code = \"gs = joblib.load(Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"SVM_gs.pkl\\\"))\\n\\nX_test_flat = X_test.squeeze().reshape((10000, 28 * 28))\\n# y_test_flat = y_test.squeeze().reshape((10000, 28 * 28))\\n\\ny_pred = SVM_gs.best_estimator_.predict(X_test_flat)\\n# accuracy = accuracy_score(y_test_flat, y_pred)\\n# conf_matrix = confusion_matrix(y_test_flat, y_pred)\";\n                var nbb_formatted_code = \"gs = joblib.load(Path(\\\"nn_mnist\\\", \\\"results\\\", \\\"SVM_gs.pkl\\\"))\\n\\nX_test_flat = X_test.squeeze().reshape((10000, 28 * 28))\\n# y_test_flat = y_test.squeeze().reshape((10000, 28 * 28))\\n\\ny_pred = SVM_gs.best_estimator_.predict(X_test_flat)\\n# accuracy = accuracy_score(y_test_flat, y_pred)\\n# conf_matrix = confusion_matrix(y_test_flat, y_pred)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            "
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629891453710
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('eyalt': virtualenv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "interpreter": {
      "hash": "45439b02310266bf7fa82639df21ee830d7f7c72a301e2dcb8170f1d4a978197"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}